## Flox Environment Manifest -----------------------------------------
##
##   _Everything_ you need to know about the _manifest_ is here:
##
##               https://flox.dev/docs/concepts/manifest
##
## -------------------------------------------------------------------
# Flox manifest version managed by Flox CLI
version = 1


## Install Packages --------------------------------------------------
[install]
curl.pkg-path = "curl"			# for sourcing README.md and helper script
curl.pkg-group = "helper-tools"
bat.pkg-path = "bat"			# for displaying README.md
bat.pkg-group = "helper-tools"
jq.pkg-path = "jq"			# for formatting json with helper script commands
jq.pkg-group = "helper-tools"
gum.pkg-path = "gum"
kafka.pkg-path = "apacheKafka"
jdk.pkg-path = "jdk"
coreutils.pkg-path = "coreutils"	# for macOS/darwin compatibility
coreutils.pkg-group = "darwin-tools"	# package group defined just for macOS/darwin
gawk.pkg-path = "gawk"			# for macOS/darwin compatibility
gawk.pkg-group = "darwin-tools"		# package group defined just for macOS/darwin
gnugrep.pkg-path = "gnugrep"		# for macOS/darwin compatibility
gnugrep.pkg-group = "gnugrep"		# package group defined just for macOS/darwin

## Environment Variables ---------------------------------------------
[vars]
# Define base variables that are always available
KAFKA_CONFIG_DIR = "$FLOX_ENV_CACHE/kafka-config"
KAFKA_LOG_DIR = "$FLOX_ENV_CACHE/kafka-logs"
KAFKA_DATA_DIR = "$FLOX_ENV_CACHE/data/kafka"

[hook]
on-activate = '''
# Create required directories
mkdir -p "$FLOX_ENV_CACHE/kafka-config"
mkdir -p "$FLOX_ENV_CACHE/kafka-logs" 
mkdir -p "$FLOX_ENV_CACHE/data/kafka"
mkdir -p "$FLOX_ENV_CACHE/kafka-message-output"
mkdir -p "$FLOX_ENV_CACHE/kafka-scripts"

# Define the hash generation correctly
generate_config_hash() {
  (
    # List of critical configuration variables that define the setup
    echo "KAFKA_MODE=$KAFKA_MODE"
    echo "KAFKA_NODE_ID=$KAFKA_NODE_ID"
    echo "KAFKA_HOST=$KAFKA_HOST"
    echo "KAFKA_PORT=$KAFKA_PORT"
    echo "KRAFT_CONTROLLER_PORT=$KRAFT_CONTROLLER_PORT"
    echo "PROCESS_ROLES=$PROCESS_ROLES"
    echo "CONTROLLER_QUORUM=$CONTROLLER_QUORUM"
    echo "KAFKA_CLUSTER_ID=$KAFKA_CLUSTER_ID"
    echo "KAFKA_REPLICATION_FACTOR=$KAFKA_REPLICATION_FACTOR" 
    echo "KAFKA_NUM_PARTITIONS=$KAFKA_NUM_PARTITIONS"
  ) | sha256sum | awk '{print $1}'
}

# Check if configuration has changed
CONFIG_HASH_FILE="$FLOX_ENV_CACHE/kafka-config/config_hash"
CURRENT_HASH=$(generate_config_hash)

# Create hash directory if it doesn't exist
mkdir -p "$(dirname "$CONFIG_HASH_FILE")"

# Detect configuration changes and reset if needed
if [ -f "$CONFIG_HASH_FILE" ]; then
  STORED_HASH=$(cat "$CONFIG_HASH_FILE")
  if [ "$CURRENT_HASH" != "$STORED_HASH" ]; then
    echo "Configuration change detected. Resetting Kafka state..."
    
    # Stop any running Kafka service (non-interactive)
    if command -v systemctl >/dev/null 2>&1 && systemctl is-active --quiet flox-kafka; then
      systemctl stop flox-kafka >/dev/null 2>&1
    fi
    
    # Clean up existing data and configuration
    rm -rf "$FLOX_ENV_CACHE/data/kafka"/*
    rm -f "$FLOX_ENV_CACHE/kafka-config/cluster_id"
    rm -f "$FLOX_ENV_CACHE/kafka_config.sh"
    rm -f "$FLOX_ENV_CACHE/kafka-config/kraft.properties"
    rm -f "$FLOX_ENV_CACHE/kafka-config/kraft.properties.base"
    
    # Create fresh directories
    mkdir -p "$FLOX_ENV_CACHE/data/kafka"
    
    # Store new hash
    echo "$CURRENT_HASH" > "$CONFIG_HASH_FILE"
    echo "Reset complete. New configuration will be applied."
  fi
else
  # First run, just store the hash
  echo "$CURRENT_HASH" > "$CONFIG_HASH_FILE"
fi

# Set Kafka home if not already set
if [ -z "$KAFKA_HOME" ]; then
  export KAFKA_HOME="$(dirname $(which kafka-server-start.sh))/.."
fi

# Set default directories
if [ -z "$KAFKA_CONFIG_DIR" ]; then
  export KAFKA_CONFIG_DIR="$FLOX_ENV_CACHE/kafka-config"
fi

if [ -z "$KAFKA_LOG_DIR" ]; then
  export KAFKA_LOG_DIR="$FLOX_ENV_CACHE/kafka-logs"
fi

if [ -z "$KAFKA_DATA_DIR" ]; then
  export KAFKA_DATA_DIR="$FLOX_ENV_CACHE/data/kafka"
fi

# Set default mode
if [ -z "$KAFKA_MODE" ]; then
  export KAFKA_MODE="kraft-combined"
fi

# Detect IP address if needed
if [ -z "$KAFKA_HOST" ]; then
  # Try to detect IP based on OS
  if [ "$(uname)" = "Darwin" ]; then
    # macOS detection
    DETECTED_IP=$(ifconfig | grep "inet " | grep -v 127.0.0.1 | awk '{print $2}' | head -n 1)
  else
    # Linux detection
    DETECTED_IP=$(hostname -I 2>/dev/null | awk '{print $1}')
    
    # Fallback methods if needed
    if [ -z "$DETECTED_IP" ]; then
      if command -v ip >/dev/null 2>&1; then
        DETECTED_IP=$(ip -4 addr | grep -v "127.0.0.1" | grep inet | awk '{print $2}' | cut -d/ -f1 | head -n 1)
      elif command -v ifconfig >/dev/null 2>&1; then
        DETECTED_IP=$(ifconfig | grep -Eo 'inet (addr:)?([0-9]*\.){3}[0-9]*' | grep -Eo '([0-9]*\.){3}[0-9]*' | grep -v '127.0.0.1' | head -n 1)
      fi
    fi
  fi
  
  # Default to localhost if detection failed
  if [ -z "$DETECTED_IP" ]; then
    DETECTED_IP="localhost"
    echo "Warning: Could not detect IP address, using localhost as fallback."
  fi
  
  export KAFKA_HOST="$DETECTED_IP"
fi

# Set default ports
if [ -z "$KAFKA_PORT" ]; then
  export KAFKA_PORT="9092"
fi

if [ -z "$KRAFT_CONTROLLER_PORT" ]; then
  export KRAFT_CONTROLLER_PORT="9093"
fi

# Set default node ID
if [ -z "$KAFKA_NODE_ID" ]; then
  export KAFKA_NODE_ID="1"
fi

# Set process roles based on mode
if [ -z "$PROCESS_ROLES" ]; then
  if [ "$KAFKA_MODE" = "kraft-combined" ]; then
    export PROCESS_ROLES="broker,controller"
  elif [ "$KAFKA_MODE" = "kraft-controller" ]; then
    export PROCESS_ROLES="controller"
  elif [ "$KAFKA_MODE" = "kraft-broker" ]; then
    export PROCESS_ROLES="broker"
  fi
fi

# Set default replication and partitions
if [ -z "$KAFKA_REPLICATION_FACTOR" ]; then
  export KAFKA_REPLICATION_FACTOR="1"
fi

if [ -z "$KAFKA_NUM_PARTITIONS" ]; then
  export KAFKA_NUM_PARTITIONS="1"
fi

# Set controller quorum if needed
if [ -z "$CONTROLLER_QUORUM" ]; then
  if [ "$KAFKA_MODE" = "kraft-combined" ] || [ "$KAFKA_MODE" = "kraft-controller" ]; then
    export CONTROLLER_QUORUM="${KAFKA_NODE_ID}@${KAFKA_HOST}:${KRAFT_CONTROLLER_PORT}"
  elif [ "$KAFKA_MODE" = "kraft-broker" ]; then
    # For broker mode, the controller quorum should NOT include our node ID
    # Default to a controller with node ID 101 (to avoid conflicts)
    CONTROLLER_NODE_ID=101
    export CONTROLLER_QUORUM="${CONTROLLER_NODE_ID}@${KAFKA_HOST}:${KRAFT_CONTROLLER_PORT}"
    echo "WARNING: Using default CONTROLLER_QUORUM=${CONTROLLER_QUORUM}"
    echo "         Please set CONTROLLER_QUORUM explicitly for proper setup."
  fi
fi

# Set client mode defaults
if [ "$KAFKA_MODE" = "client" ]; then
  if [ -z "$BOOTSTRAP_SERVERS" ]; then
    export BOOTSTRAP_SERVERS="localhost:9092"
  fi
  
  if [ -z "$CLIENT_TYPE" ]; then
    export CLIENT_TYPE="consumer"
  fi
  
  if [ -z "$KAFKA_TOPICS" ]; then
    export KAFKA_TOPICS="flox-is-great"
  fi
  
  if [ -z "$KAFKA_CLIENT_COUNT" ]; then
    export KAFKA_CLIENT_COUNT="1"
  fi
  
  if [ -z "$KAFKA_CLIENT_PARALLEL" ]; then
    export KAFKA_CLIENT_PARALLEL="false"
  fi
  
  if [ -z "$KAFKA_MESSAGE_PROCESSING_MODE" ]; then
    export KAFKA_MESSAGE_PROCESSING_MODE="echo"
  fi
  
  if [ -z "$KAFKA_MESSAGE_OUTPUT_DIR" ]; then
    export KAFKA_MESSAGE_OUTPUT_DIR="$FLOX_ENV_CACHE/kafka-message-output"
  fi
  
  if [ -z "$KAFKA_SCRIPTS_DIR" ]; then
    export KAFKA_SCRIPTS_DIR="$FLOX_ENV_CACHE/kafka-scripts"
  fi
  
  if [ -z "$KAFKA_FILE_APPEND" ]; then
    export KAFKA_FILE_APPEND="true"
  fi
fi

# Create kafka_config.sh file
echo "# Kafka config generated by Flox environment" > "$FLOX_ENV_CACHE/kafka_config.sh"
echo "KAFKA_MODE=\"$KAFKA_MODE\"" >> "$FLOX_ENV_CACHE/kafka_config.sh"
echo "KAFKA_CONFIG_DIR=\"$KAFKA_CONFIG_DIR\"" >> "$FLOX_ENV_CACHE/kafka_config.sh" 
echo "KAFKA_LOG_DIR=\"$KAFKA_LOG_DIR\"" >> "$FLOX_ENV_CACHE/kafka_config.sh"
echo "KAFKA_DATA_DIR=\"$KAFKA_DATA_DIR\"" >> "$FLOX_ENV_CACHE/kafka_config.sh"

# Add KRaft mode settings
if [ "$KAFKA_MODE" = "kraft-combined" ] || [ "$KAFKA_MODE" = "kraft-controller" ] || [ "$KAFKA_MODE" = "kraft-broker" ]; then
  echo "KAFKA_NODE_ID=\"$KAFKA_NODE_ID\"" >> "$FLOX_ENV_CACHE/kafka_config.sh"
  echo "KAFKA_HOST=\"$KAFKA_HOST\"" >> "$FLOX_ENV_CACHE/kafka_config.sh"
  echo "KAFKA_PORT=\"$KAFKA_PORT\"" >> "$FLOX_ENV_CACHE/kafka_config.sh"
  echo "KRAFT_CONTROLLER_PORT=\"$KRAFT_CONTROLLER_PORT\"" >> "$FLOX_ENV_CACHE/kafka_config.sh"
  echo "PROCESS_ROLES=\"$PROCESS_ROLES\"" >> "$FLOX_ENV_CACHE/kafka_config.sh"
  
  # Add controller quorum if set
  if [ -n "$CONTROLLER_QUORUM" ]; then
    echo "CONTROLLER_QUORUM=\"$CONTROLLER_QUORUM\"" >> "$FLOX_ENV_CACHE/kafka_config.sh"
  fi
  
  # Handle cluster ID
  if [ -f "$KAFKA_CONFIG_DIR/cluster_id" ]; then
    CLUSTER_ID=$(cat "$KAFKA_CONFIG_DIR/cluster_id")
    echo "KAFKA_CLUSTER_ID=\"$CLUSTER_ID\"" >> "$FLOX_ENV_CACHE/kafka_config.sh"
  elif [ -n "$KAFKA_CLUSTER_ID" ]; then
    echo "$KAFKA_CLUSTER_ID" > "$KAFKA_CONFIG_DIR/cluster_id"
    echo "KAFKA_CLUSTER_ID=\"$KAFKA_CLUSTER_ID\"" >> "$FLOX_ENV_CACHE/kafka_config.sh"
  elif [ "$KAFKA_MODE" = "kraft-controller" ] || [ "$KAFKA_MODE" = "kraft-combined" ]; then
    GENERATED_CLUSTER_ID=$(kafka-storage.sh random-uuid)
    echo "$GENERATED_CLUSTER_ID" > "$KAFKA_CONFIG_DIR/cluster_id"
    echo "KAFKA_CLUSTER_ID=\"$GENERATED_CLUSTER_ID\"" >> "$FLOX_ENV_CACHE/kafka_config.sh"
  fi

  # Create kraft.properties.base file
  echo "# KRaft config generated by Flox" > "$KAFKA_CONFIG_DIR/kraft.properties.base"
  echo "node.id=$KAFKA_NODE_ID" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
  echo "process.roles=$PROCESS_ROLES" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
  
  # Add listeners based on role
  if [ "$PROCESS_ROLES" = "broker,controller" ]; then
    echo "listeners=PLAINTEXT://$KAFKA_HOST:$KAFKA_PORT,CONTROLLER://$KAFKA_HOST:$KRAFT_CONTROLLER_PORT" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
    echo "advertised.listeners=PLAINTEXT://$KAFKA_HOST:$KAFKA_PORT" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
  elif [ "$PROCESS_ROLES" = "broker" ]; then
    echo "listeners=PLAINTEXT://$KAFKA_HOST:$KAFKA_PORT" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
    echo "advertised.listeners=PLAINTEXT://$KAFKA_HOST:$KAFKA_PORT" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
  else
    # controller-only
    echo "listeners=CONTROLLER://$KAFKA_HOST:$KRAFT_CONTROLLER_PORT" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
  fi
  
  # Add security protocols and other settings
  echo "listener.security.protocol.map=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
  echo "controller.listener.names=CONTROLLER" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
  echo "controller.quorum.voters=$CONTROLLER_QUORUM" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
  echo "log.dirs=$KAFKA_DATA_DIR" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
  echo "default.replication.factor=$KAFKA_REPLICATION_FACTOR" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
  echo "num.partitions=$KAFKA_NUM_PARTITIONS" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
  
  # Set additional properties with defaults if not specified
  if [ -n "$KAFKA_LOG_RETENTION_HOURS" ]; then
    echo "log.retention.hours=$KAFKA_LOG_RETENTION_HOURS" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
  else
    echo "log.retention.hours=168" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
  fi
  
  if [ -n "$KAFKA_LOG_SEGMENT_BYTES" ]; then
    echo "log.segment.bytes=$KAFKA_LOG_SEGMENT_BYTES" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
  else
    echo "log.segment.bytes=1073741824" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
  fi
  
  if [ -n "$KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS" ]; then
    echo "log.retention.check.interval.ms=$KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
  else
    echo "log.retention.check.interval.ms=300000" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
  fi
  
  if [ -n "$KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR" ]; then
    echo "offsets.topic.replication.factor=$KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
  else
    echo "offsets.topic.replication.factor=1" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
  fi
  
  if [ -n "$KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR" ]; then
    echo "transaction.state.log.replication.factor=$KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
  else
    echo "transaction.state.log.replication.factor=1" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
  fi
  
  if [ -n "$KAFKA_TRANSACTION_STATE_LOG_MIN_ISR" ]; then
    echo "transaction.state.log.min.isr=$KAFKA_TRANSACTION_STATE_LOG_MIN_ISR" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
  else
    echo "transaction.state.log.min.isr=1" >> "$KAFKA_CONFIG_DIR/kraft.properties.base"
  fi

# Add client mode settings
elif [ "$KAFKA_MODE" = "client" ]; then
  echo "BOOTSTRAP_SERVERS=\"$BOOTSTRAP_SERVERS\"" >> "$FLOX_ENV_CACHE/kafka_config.sh"
  echo "CLIENT_TYPE=\"$CLIENT_TYPE\"" >> "$FLOX_ENV_CACHE/kafka_config.sh"
  echo "KAFKA_TOPICS=\"$KAFKA_TOPICS\"" >> "$FLOX_ENV_CACHE/kafka_config.sh"
  echo "KAFKA_CLIENT_COUNT=\"$KAFKA_CLIENT_COUNT\"" >> "$FLOX_ENV_CACHE/kafka_config.sh"
  echo "KAFKA_CLIENT_PARALLEL=\"$KAFKA_CLIENT_PARALLEL\"" >> "$FLOX_ENV_CACHE/kafka_config.sh"
  echo "KAFKA_MESSAGE_PROCESSING_MODE=\"$KAFKA_MESSAGE_PROCESSING_MODE\"" >> "$FLOX_ENV_CACHE/kafka_config.sh"
  echo "KAFKA_MESSAGE_OUTPUT_DIR=\"$KAFKA_MESSAGE_OUTPUT_DIR\"" >> "$FLOX_ENV_CACHE/kafka_config.sh"
  echo "KAFKA_SCRIPTS_DIR=\"$KAFKA_SCRIPTS_DIR\"" >> "$FLOX_ENV_CACHE/kafka_config.sh"
  echo "KAFKA_FILE_APPEND=\"$KAFKA_FILE_APPEND\"" >> "$FLOX_ENV_CACHE/kafka_config.sh"
fi

# Find JAVA_HOME if not set
if [ -z "$JAVA_HOME" ]; then
  export JAVA_HOME="$(dirname $(dirname $(which java)))"
fi

# Display current configuration
echo "Kafka Environment Configuration:"
echo "  Mode:            $KAFKA_MODE"
if [ "$KAFKA_MODE" = "kraft-combined" ] || [ "$KAFKA_MODE" = "kraft-controller" ] || [ "$KAFKA_MODE" = "kraft-broker" ]; then
  echo "  Node ID:         $KAFKA_NODE_ID"
  echo "  Host:            $KAFKA_HOST"
  if [ "$KAFKA_MODE" != "kraft-controller" ]; then 
    echo "  Broker Port:     $KAFKA_PORT"
  fi
  if [ "$KAFKA_MODE" != "kraft-broker" ]; then
    echo "  Controller Port: $KRAFT_CONTROLLER_PORT"
  fi
  echo "  Process Roles:   $PROCESS_ROLES"
  if [ -f "$KAFKA_CONFIG_DIR/cluster_id" ]; then
    echo "  Cluster ID:      $(cat "$KAFKA_CONFIG_DIR/cluster_id")"
  fi
elif [ "$KAFKA_MODE" = "client" ]; then
  echo "  Bootstrap Servers: $BOOTSTRAP_SERVERS"
  echo "  Client Type:       $CLIENT_TYPE"
  echo "  Topics:            $KAFKA_TOPICS"
fi
'''

[profile]

## Services ----------------------------------------------------------
[services]
kafka.command = '''
# creates required directories
mkdir -p "$FLOX_ENV_CACHE/kafka-logs"
mkdir -p "$FLOX_ENV_CACHE/kafka-config"
mkdir -p "$FLOX_ENV_CACHE/data/kafka"
mkdir -p "$FLOX_ENV_CACHE/kafka-message-output"
mkdir -p "$FLOX_ENV_CACHE/kafka-scripts"

# checks for config changes / resets kafka_config.sh
CONFIG_HASH_FILE="$FLOX_ENV_CACHE/kafka-config/config_hash"
if [ ! -f "$CONFIG_HASH_FILE" ]; then
  echo "WARNING: Configuration hash file not found. Service may not start correctly." | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
fi

# verifies config file exists
if [ ! -f "$FLOX_ENV_CACHE/kafka_config.sh" ]; then
    echo "ERROR: kafka_config.sh not found. Please run 'bootstrap' first." | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
    exit 1
fi

# loads config - uses set -a to auto-export all variables
echo "Loading config from: $FLOX_ENV_CACHE/kafka_config.sh" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
if [ -f "$FLOX_ENV_CACHE/kafka_config.sh" ]; then
    set -a
    . "$FLOX_ENV_CACHE/kafka_config.sh"
    set +a
    echo "config loaded successfully" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
else
    echo "ERROR: config file not found" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
    exit 1
fi

# logs debug info to verify variables
echo "DEBUG: After sourcing kafka_config.sh" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
echo "KAFKA_MODE=${KAFKA_MODE}" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
echo "BOOTSTRAP_SERVERS=${BOOTSTRAP_SERVERS}" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
echo "CLIENT_TYPE=${CLIENT_TYPE}" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
echo "KAFKA_CONFIG_DIR=${KAFKA_CONFIG_DIR}" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
echo "KAFKA_TOPICS=${KAFKA_TOPICS}" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
echo "KAFKA_CLUSTER_ID=${KAFKA_CLUSTER_ID}" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"

# Explicitly load cluster ID from file if not in environment and file exists
if [ -z "$KAFKA_CLUSTER_ID" ] && [ -f "$KAFKA_CONFIG_DIR/cluster_id" ]; then
    KAFKA_CLUSTER_ID=$(cat "$KAFKA_CONFIG_DIR/cluster_id")
    echo "Loaded cluster ID from file: $KAFKA_CLUSTER_ID" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
fi

# performs mode-specific validation
if [ "$KAFKA_MODE" = "client" ]; then
    # validates client mode variables
    if [ -z "$KAFKA_MODE" ] || [ -z "$BOOTSTRAP_SERVERS" ]; then
        echo "ERROR: Critical variables not set for client mode. Please run 'bootstrap' first." | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
        echo "KAFKA_MODE='$KAFKA_MODE', BOOTSTRAP_SERVERS='$BOOTSTRAP_SERVERS'" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
        exit 1
    fi
else
    # validates broker/controller mode variables
    if [ -z "$KAFKA_MODE" ] || [ -z "$KAFKA_NODE_ID" ] || [ -z "$KAFKA_HOST" ]; then
        echo "ERROR: Critical variables not set. Please run 'bootstrap' first." | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
        echo "KAFKA_MODE='$KAFKA_MODE', KAFKA_NODE_ID='$KAFKA_NODE_ID', KAFKA_HOST='$KAFKA_HOST'" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
        exit 1
    fi

    # makes sure node ID is not in controller quorum (broker mode only)
    if [ "$KAFKA_MODE" = "kraft-broker" ]; then
        if [[ "$CONTROLLER_QUORUM" == *"${KAFKA_NODE_ID}@"* ]]; then
            echo "ERROR: In broker-only mode, the broker's node ID ($KAFKA_NODE_ID) cannot be part of the controller quorum ($CONTROLLER_QUORUM)" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
            exit 1
        fi
    fi
fi

# sets default for JMX cleanup
export KAFKA_CLEANUP_JMX="${KAFKA_CLEANUP_JMX:-true}"

# logs config
echo "=== Kafka Service Startup ===" > "$FLOX_ENV_CACHE/kafka-logs/service.log"
echo "Starting at $(date)" >> "$FLOX_ENV_CACHE/kafka-logs/service.log"
echo "KAFKA_MODE = $KAFKA_MODE" >> "$FLOX_ENV_CACHE/kafka-logs/service.log"

# handles client mode operation
if [ "$KAFKA_MODE" = "client" ]; then
    echo "Starting in client mode with $CLIENT_TYPE" >> "$FLOX_ENV_CACHE/kafka-logs/service.log"
    echo "Bootstrap servers: $BOOTSTRAP_SERVERS" >> "$FLOX_ENV_CACHE/kafka-logs/service.log"
    echo "Client count: ${KAFKA_CLIENT_COUNT:-1}" >> "$FLOX_ENV_CACHE/kafka-logs/service.log"
    echo "Running in parallel: ${KAFKA_CLIENT_PARALLEL:-true}" >> "$FLOX_ENV_CACHE/kafka-logs/service.log"
    
    # sets defaults for client mode
    KAFKA_CLIENT_COUNT=${KAFKA_CLIENT_COUNT:-1}
    KAFKA_CLIENT_PARALLEL=${KAFKA_CLIENT_PARALLEL:-true}
    KAFKA_FILE_APPEND=${KAFKA_FILE_APPEND:-true}
    KAFKA_MESSAGE_PROCESSING_MODE=${KAFKA_MESSAGE_PROCESSING_MODE:-echo}
    KAFKA_MESSAGE_OUTPUT_DIR=${KAFKA_MESSAGE_OUTPUT_DIR:-$FLOX_ENV_CACHE/kafka-message-output}
    KAFKA_SCRIPTS_DIR=${KAFKA_SCRIPTS_DIR:-$FLOX_ENV_CACHE/kafka-scripts}
    
    # stores background process IDs
    declare -a client_pids
    
    # runs a client instance
    run_client_instance() {
        local client_id=$1
        local log_file="$FLOX_ENV_CACHE/kafka-logs/client_${client_id}.log"
        
        echo "Starting client instance $client_id (type: $CLIENT_TYPE, mode: $KAFKA_MESSAGE_PROCESSING_MODE)" | tee -a "$log_file"
        
        # creates temporary properties file
        local client_props_file="$FLOX_ENV_CACHE/kafka-config/client_${client_id}.properties"
        
        # exports env vars and runs client
        case "$CLIENT_TYPE" in
            "consumer")
                # generates consumer client.properties
                cat > "$client_props_file" <<-ENDOFCONSUMER
bootstrap.servers=$BOOTSTRAP_SERVERS
group.id=flox-consumer-group-$client_id
auto.offset.reset=earliest
enable.auto.commit=true
auto.commit.interval.ms=1000
key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
ENDOFCONSUMER

                case "$KAFKA_MESSAGE_PROCESSING_MODE" in
                    "echo")
                        env BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" KAFKA_TOPICS="$KAFKA_TOPICS" \
                            kafka-console-consumer.sh --bootstrap-server "$BOOTSTRAP_SERVERS" \
                            --topic "$KAFKA_TOPICS" \
                            --consumer.config "$client_props_file" \
                            2>&1 | tee -a "$log_file"
                        ;;
                    "file")
                        output_file="$KAFKA_MESSAGE_OUTPUT_DIR/client_${client_id}_messages.txt"
                        if [ "$KAFKA_FILE_APPEND" = "true" ]; then
                            env BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" KAFKA_TOPICS="$KAFKA_TOPICS" \
                                kafka-console-consumer.sh --bootstrap-server "$BOOTSTRAP_SERVERS" \
                                --topic "$KAFKA_TOPICS" \
                                --consumer.config "$client_props_file" \
                                2>> "$log_file" >> "$output_file"
                        else
                            env BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" KAFKA_TOPICS="$KAFKA_TOPICS" \
                                kafka-console-consumer.sh --bootstrap-server "$BOOTSTRAP_SERVERS" \
                                --topic "$KAFKA_TOPICS" \
                                --consumer.config "$client_props_file" \
                                2>> "$log_file" > "$output_file"
                        fi
                        ;;
                    "script")
                        script_file="$KAFKA_SCRIPTS_DIR/process_messages.sh"
                        if [ -x "$script_file" ]; then
                            env BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" KAFKA_TOPICS="$KAFKA_TOPICS" \
                                kafka-console-consumer.sh --bootstrap-server "$BOOTSTRAP_SERVERS" \
                                --topic "$KAFKA_TOPICS" \
                                --consumer.config "$client_props_file" \
                                2>> "$log_file" | "$script_file" 2>&1 | tee -a "$log_file"
                        else
                            echo "ERROR: Processing script not found or not executable: $script_file" | tee -a "$log_file"
                            exit 1
                        fi
                        ;;
                esac
                ;;
            "producer")
                # Client mode implementations would continue here
                # Similar to original script
                ;;
        esac
    }
    
    # Original client mode logic would continue here
    # ...
    
else
    # handles broker/controller mode logic
    echo "Starting Kafka in $KAFKA_MODE mode" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
    echo "KAFKA_NODE_ID = $KAFKA_NODE_ID" >> "$FLOX_ENV_CACHE/kafka-logs/service.log"
    echo "KAFKA_HOST = $KAFKA_HOST" >> "$FLOX_ENV_CACHE/kafka-logs/service.log"
    echo "KAFKA_PORT = $KAFKA_PORT" >> "$FLOX_ENV_CACHE/kafka-logs/service.log"
    echo "KRAFT_CONTROLLER_PORT = $KRAFT_CONTROLLER_PORT" >> "$FLOX_ENV_CACHE/kafka-logs/service.log"
    echo "KAFKA_CLUSTER_ID = $KAFKA_CLUSTER_ID" >> "$FLOX_ENV_CACHE/kafka-logs/service.log"
    echo "KAFKA_DATA_DIR = $KAFKA_DATA_DIR" >> "$FLOX_ENV_CACHE/kafka-logs/service.log"

    # ensures data directory exists
    mkdir -p "$KAFKA_DATA_DIR"

    # regenerates kraft.properties from base file
    if [ -f "$KAFKA_CONFIG_DIR/kraft.properties.base" ]; then
        cp "$KAFKA_CONFIG_DIR/kraft.properties.base" "$KAFKA_CONFIG_DIR/kraft.properties"
    else
        echo "ERROR: kraft.properties.base not found" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
        exit 1
    fi
    
    # formats storage if meta.properties not exist
    if [ ! -f "$KAFKA_DATA_DIR/meta.properties" ]; then
        echo "  ℹ️  Formatting KRaft storage directory (first-time setup)" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
        echo "  ℹ️  Using cluster ID: $KAFKA_CLUSTER_ID" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"

        if env KAFKA_CLUSTER_ID="$KAFKA_CLUSTER_ID" KAFKA_DATA_DIR="$KAFKA_DATA_DIR" kafka-storage.sh format --cluster-id "$KAFKA_CLUSTER_ID" --config "$KAFKA_CONFIG_DIR/kraft.properties"; then
            echo "  ✓ Storage formatted successfully" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
        else
            echo "  ❌ ERROR: Storage format failed" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
            exit 1
        fi
    else
        echo "  ✓ Using existing KRaft storage directory" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
    fi

    # starts kafka
    echo "" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
    echo "Starting Kafka $KAFKA_MODE service..." | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
    echo "  - Node ID: $KAFKA_NODE_ID" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
    echo "  - Host: $KAFKA_HOST" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
    
    if [ "$KAFKA_MODE" = "kraft-controller" ]; then
        echo "  - Controller Port: $KRAFT_CONTROLLER_PORT" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
        echo "  - Quorum: $CONTROLLER_QUORUM" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
    elif [ "$KAFKA_MODE" = "kraft-broker" ]; then
        echo "  - Broker Port: $KAFKA_PORT" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
        echo "  - Controller Quorum: $CONTROLLER_QUORUM" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
    else  # kraft-combined
        echo "  - Broker Port: $KAFKA_PORT" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
        echo "  - Controller Port: $KRAFT_CONTROLLER_PORT" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
    fi
    
    echo "  - Data directory: $KAFKA_DATA_DIR" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
    echo "  - Config file: $KAFKA_CONFIG_DIR/kraft.properties" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
    echo "" | tee -a "$FLOX_ENV_CACHE/kafka-logs/startup.log"
    
    # Explicitly set all needed env vars when starting kafka
    exec env KAFKA_CLUSTER_ID="$KAFKA_CLUSTER_ID" \
             KAFKA_NODE_ID="$KAFKA_NODE_ID" \
             KAFKA_HOST="$KAFKA_HOST" \
             KAFKA_PORT="$KAFKA_PORT" \
             KAFKA_DATA_DIR="$KAFKA_DATA_DIR" \
             KRAFT_CONTROLLER_PORT="$KRAFT_CONTROLLER_PORT" \
             KAFKA_CONFIG_DIR="$KAFKA_CONFIG_DIR" \
             KAFKA_LOG_DIR="$KAFKA_LOG_DIR" \
             JAVA_HOME="$JAVA_HOME" \
             kafka-server-start.sh "$KAFKA_CONFIG_DIR/kraft.properties"
fi
'''

## Other Environment Options -----------------------------------------
[options]
# Systems that environment is compatible with
systems = [
  "aarch64-linux",
  "x86_64-linux",
  "aarch64-darwin",
  "x86_64-darwin",
]
